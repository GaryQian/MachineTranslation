#!/usr/bin/env python
import optparse
import sys
import models
from collections import namedtuple
from mergeSplit import pharoahToGreedy, mergeSentence, splitSentence
from swap import swap
from move import move
from randomShuffle import randomShuffle


def extract_english_greedy(current):
  return " ".join([h.phrase for h in current])

def score(src, sen, lm, tm, l1, l2, l3):
    #calculate Lmprob
    lm_state = lm.begin()
    lm_logprob = 0.0
    for word in extract_english_greedy(sen).split(" ") + ["</s>"]:
      (lm_state, word_logprob) = lm.score(lm_state, word)
      lm_logprob += word_logprob
    
    '''lm_state = lm.begin() # initial state is always <s>
    lmprob = 0.0
    for word in extract_english_greedy(sen):
        (lm_state, word_logprob) = lm.score(lm_state, word)
        lmprob += word_logprob
    lmprob += lm.end(lm_state) # transition to </s>, can also use lm.score(lm_state, "</s>")[1]'''
    #calculate tmProb

    tmProb = 0.0
    for gh in sen:
        fphrase = tuple(src[gh.frindex[0]:gh.frindex[1]])
        for t in tm[fphrase]:
            if t.english == gh.phrase:
                tmProb += t.logprob

    prob = (l1*lm_logprob) + (l2*tmProb) - (l3* len(sen)) 
    return prob




optparser = optparse.OptionParser()
optparser.add_option("-i", "--input", dest="input", default="data/input", help="File containing sentences to translate (default=data/input)")
optparser.add_option("-t", "--translation-model", dest="tm", default="data/tm", help="File containing translation model (default=data/tm)")
optparser.add_option("-l", "--language-model", dest="lm", default="data/lm", help="File containing ARPA-format language model (default=data/lm)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint, type="int", help="Number of sentences to decode (default=no limit)")
optparser.add_option("-k", "--translations-per-phrase", dest="k", default=1, type="int", help="Limit on number of translations to consider per phrase (default=1)")
optparser.add_option("-s", "--stack-size", dest="s", default=1, type="int", help="Maximum stack size (default=1)")
optparser.add_option("-v", "--verbose", dest="verbose", action="store_true", default=False,  help="Verbose mode (default=off)")
opts = optparser.parse_args()[0]

tm = models.TM(opts.tm, opts.k)
lm = models.LM(opts.lm)
french = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

greedyHyp = namedtuple('greedyHyp', ('frindex, phrase'))

# tm should translate unknown words as-is with probability 1
for word in set(sum(french,())):
  if (word,) not in tm:
    tm[(word,)] = [models.phrase(word, 0.0)]

sys.stderr.write("Decoding %s...\n" % (opts.input,))
for (i,f) in enumerate(french):
  if i > 9:
    break
  # The following code implements a monotone decoding
  # algorithm (one that doesn't permute the target phrases).
  # Hence all hypotheses in stacks[i] represent translations of 
  # the first i words of the input sentence. You should generalize
  # this so that they can represent translations of *any* i words.
  hypothesis = namedtuple("hypothesis", "logprob, lm_state, predecessor, phrase, frindex")
  initial_hypothesis = hypothesis(0.0, lm.begin(), None, None, None)
  stacks = [{} for _ in f] + [{}]
  stacks[0][lm.begin()] = initial_hypothesis
  for i, stack in enumerate(stacks[:-1]):
    for h in sorted(stack.itervalues(),key=lambda h: -h.logprob)[:opts.s]: # prune
      for j in xrange(i+1,len(f)+1):
        if f[i:j] in tm:
          for phrase in tm[f[i:j]]:
            #Find h for new predecessor
            if h.predecessor is not None and h.lm_state is not None:
              logprob = h.predecessor.logprob + phrase.logprob
              lm_state = h.predecessor.lm_state
              for word in phrase.english.split():
                (lm_state, word_logprob) = lm.score(lm_state, word)
                logprob += word_logprob
                logprob += lm.end(lm_state) if j == len(f) else 0.0
              h2 = hypothesis(logprob, lm_state, h.predecessor, phrase, (i, j))
              if lm_state not in stacks[i-1] or stacks[i-1][lm_state].logprob < logprob: # second case is recombination
                stacks[i-1][lm_state] = h2
                
#===================================================================================================================
              #Find h for swapped pair
              logprob = h2.logprob + h.phrase.logprob
              lm_state = h2.lm_state
              for word in h.phrase.english.split():
                (lm_state, word_logprob) = lm.score(lm_state, word)
                logprob += word_logprob
              logprob += lm.end(lm_state) if j == len(f) else 0.0
              new_hypothesis = hypothesis(logprob, lm_state, h2, h.phrase, h.frindex)
              if lm_state not in stacks[j] or stacks[j][lm_state].logprob < logprob: # second case is recombination
                stacks[j][lm_state] = new_hypothesis
            
#===================================================================================================================
            logprob = h.logprob + phrase.logprob
            lm_state = h.lm_state
            for word in phrase.english.split():
              (lm_state, word_logprob) = lm.score(lm_state, word)
              logprob += word_logprob
            logprob += lm.end(lm_state) if j == len(f) else 0.0
            new_hypothesis = hypothesis(logprob, lm_state, h, phrase, (i, j))
            if lm_state not in stacks[j] or stacks[j][lm_state].logprob < logprob: # second case is recombination
              stacks[j][lm_state] = new_hypothesis
  def extract_english(h): 
    return "" if h.predecessor is None else "%s%s " % (extract_english(h.predecessor), h.phrase.english)
  winner = max(stacks[-1].itervalues(), key=lambda h: h.logprob)
  
  current = pharoahToGreedy(winner)
  maxiters = 100
  #print extract_english(winner)
  while (maxiters > 0):
    maxiters -= 1
    s_current = score(f, current, lm, tm, 1, 1, 0)
    #print s_current
    s = s_current
    neighbors = []
    neighbors += swap(current)
    #neighbors += move(current) #Causes alignment issues
    neighbors += mergeSentence(current, f, tm)
    #neighbors += splitSentence(current, f, tm)
    neighbors += randomShuffle(current, 10000)
    #print len(neighbors)
    best = current
    for h in neighbors:
      c = score(f,h,lm,tm,1,1,0)
      #print c - s
      if c > s and c - s > 10e-10:
        s = c
        best = h
        #print 'NewBest: ' +  extract_english_greedy(best)
    if s == s_current:
      break
    else:
      current = best

  #print extract_english(winner)
  print extract_english_greedy(current)

  if opts.verbose:
    def extract_tm_logprob(h):
      return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)
    tm_logprob = extract_tm_logprob(winner)
    sys.stderr.write("LM = %f, TM = %f, Total = %f\n" % 
      (winner.logprob - tm_logprob, tm_logprob, winner.logprob))
  
